{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec = gensim.downloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_fd = open('raw_data.json')\n",
    "raw_data = json.load(raw_data_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Creation Fn's\n",
    "def example(row):\n",
    "    print(row.name)\n",
    "    return row\n",
    "\n",
    "\n",
    "def question_matching(row):\n",
    "    keywords = {\n",
    "        'q0': set(['load', 'dataset', 'csv', 'file']),\n",
    "        'q1': set(['shape', 'summary', 'head', 'map', 'missing', 'label']),\n",
    "        'q2': set(['shuffle', 'seperate', 'split', 'training', '80', '20']),\n",
    "        'q3': set(['correlation', 'feature', 'selection', 'hypothetical']),\n",
    "        'q4': set(['hyperparameter', 'tune', 'gridsearchcv']),\n",
    "        'q5': set(['retrain', 'hyperparameter', 'decision', 'tree', 'plot']),\n",
    "        'q6': set(['predict', 'classification', 'accuracy', 'confusion', 'matrix']),\n",
    "        'q7': set(['information', 'gain', 'entropy', 'formula'])\n",
    "    }\n",
    "    name = row.name\n",
    "    prompt_answer_pairs = raw_data.get(name)\n",
    "\n",
    "    question_dict = {key: 0 for key in keywords}\n",
    "    for pair in prompt_answer_pairs:\n",
    "        prompt_set = set(pair[0].split())\n",
    "        match_counts = {key: 0 for key in keywords}\n",
    "\n",
    "        for question_key, keywords_set in keywords.items():\n",
    "            match_counts[question_key] += len(prompt_set.intersection(keywords_set))\n",
    "\n",
    "        max_match = max(match_counts.values())\n",
    "        for key, value in match_counts.items():\n",
    "            if value == max_match:\n",
    "                question_dict[key] += 1\n",
    "\n",
    "    for i in range(0, 8):\n",
    "        row[f'question_match_{i}'] = question_dict[f'q{i}']\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def length_and_count(row):\n",
    "    prompt_sum_of_words = 0\n",
    "    answer_sum_of_words = 0\n",
    "    for prompt, answer in raw_data[row.name]:\n",
    "        prompt_sum_of_words += len(prompt)\n",
    "        answer_sum_of_words += len(answer)\n",
    "\n",
    "    pair_count = len(raw_data[row.name])\n",
    "    row['pair_count'] = pair_count\n",
    "    row['avg_prompt_length'] = prompt_sum_of_words / pair_count\n",
    "    row['avg_answer_length'] = answer_sum_of_words / pair_count\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def vectorized_prompts(row):\n",
    "    key = row.name\n",
    "    prompt_answer_pairs = raw_data[key]\n",
    "    prompt_vector = np.zeros(word_to_vec.vector_size)\n",
    "\n",
    "    for each_pair in prompt_answer_pairs:\n",
    "        text = each_pair[0]\n",
    "        words = text.split()\n",
    "        word_vectors = []\n",
    "\n",
    "        for word in words:\n",
    "            if word in word_to_vec:\n",
    "                word_vectors.append(word_to_vec[word])\n",
    "\n",
    "        if word_vectors:  # Calculate the average of word vectors along the columns (axis=0)\n",
    "            prompt_vector = np.mean(word_vectors, axis=0)\n",
    "\n",
    "    for i, val in enumerate(prompt_vector):\n",
    "        row[f\"prompt_vector_{i}\"] = prompt_vector[i]\n",
    "    return row\n",
    "\n",
    "\n",
    "def vectorized_answers(row):\n",
    "    key = row.name\n",
    "    prompt_answer_pairs = raw_data[key]\n",
    "    prompt_vector = np.zeros(word_to_vec.vector_size)\n",
    "\n",
    "    for each_pair in prompt_answer_pairs:\n",
    "        text = each_pair[1]\n",
    "        words = text.split()\n",
    "        word_vectors = []\n",
    "\n",
    "        for word in words:\n",
    "            if word in word_to_vec:\n",
    "                word_vectors.append(word_to_vec[word])\n",
    "\n",
    "        if word_vectors:  # Calculate the average of word vectors along the columns (axis=0)\n",
    "            prompt_vector = np.mean(word_vectors, axis=0)\n",
    "\n",
    "    for i, val in enumerate(prompt_vector):\n",
    "        row[f\"answer_vector_{i}\"] = prompt_vector[i]\n",
    "    return row\n",
    "\n",
    "\n",
    "# Row processing\n",
    "def our_super_great_row_processor(row):\n",
    "    row = question_matching(row)\n",
    "    row = length_and_count(row)\n",
    "    row = vectorized_prompts(row)\n",
    "    row = vectorized_answers(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_vector_0</th>\n",
       "      <th>prompt_vector_1</th>\n",
       "      <th>prompt_vector_2</th>\n",
       "      <th>prompt_vector_3</th>\n",
       "      <th>prompt_vector_4</th>\n",
       "      <th>prompt_vector_5</th>\n",
       "      <th>prompt_vector_6</th>\n",
       "      <th>prompt_vector_7</th>\n",
       "      <th>prompt_vector_8</th>\n",
       "      <th>prompt_vector_9</th>\n",
       "      <th>...</th>\n",
       "      <th>question_match_2</th>\n",
       "      <th>question_match_3</th>\n",
       "      <th>question_match_4</th>\n",
       "      <th>question_match_5</th>\n",
       "      <th>question_match_6</th>\n",
       "      <th>question_match_7</th>\n",
       "      <th>pair_count</th>\n",
       "      <th>avg_prompt_length</th>\n",
       "      <th>avg_answer_length</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b73f91f8-732f-4a48-bcbd-eadbbb457a94</th>\n",
       "      <td>-0.105305</td>\n",
       "      <td>0.146404</td>\n",
       "      <td>0.244801</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>-0.100589</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.184923</td>\n",
       "      <td>0.107906</td>\n",
       "      <td>-0.105608</td>\n",
       "      <td>0.104179</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>455.941176</td>\n",
       "      <td>1580.352941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746b8f06-1e89-43b8-b73c-1121eecfc854</th>\n",
       "      <td>-0.099691</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.297639</td>\n",
       "      <td>-0.162343</td>\n",
       "      <td>-0.302724</td>\n",
       "      <td>0.090270</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.268344</td>\n",
       "      <td>-0.027193</td>\n",
       "      <td>0.128519</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30283b91-7fc3-4125-985b-b441f0f489d6</th>\n",
       "      <td>-0.233918</td>\n",
       "      <td>0.285974</td>\n",
       "      <td>0.382238</td>\n",
       "      <td>0.136774</td>\n",
       "      <td>0.157068</td>\n",
       "      <td>0.194427</td>\n",
       "      <td>0.194111</td>\n",
       "      <td>0.320898</td>\n",
       "      <td>-0.298705</td>\n",
       "      <td>0.203647</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>509.285714</td>\n",
       "      <td>1653.642857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9</th>\n",
       "      <td>-0.247697</td>\n",
       "      <td>0.323605</td>\n",
       "      <td>0.214531</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>-0.090610</td>\n",
       "      <td>0.141679</td>\n",
       "      <td>0.263739</td>\n",
       "      <td>0.114925</td>\n",
       "      <td>-0.068034</td>\n",
       "      <td>-0.129276</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>159.030000</td>\n",
       "      <td>1459.850000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106ffe99-c787-4d09-9076-4ba411eb68b1</th>\n",
       "      <td>-0.418465</td>\n",
       "      <td>0.338650</td>\n",
       "      <td>0.194245</td>\n",
       "      <td>-0.311205</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>-0.248920</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>-0.200436</td>\n",
       "      <td>-0.139080</td>\n",
       "      <td>-0.193729</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>215.360000</td>\n",
       "      <td>1572.080000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b9cf078-c56b-4020-9197-cd9f7d4f909c</th>\n",
       "      <td>-0.132189</td>\n",
       "      <td>0.299466</td>\n",
       "      <td>0.317161</td>\n",
       "      <td>-0.080648</td>\n",
       "      <td>-0.029858</td>\n",
       "      <td>0.324425</td>\n",
       "      <td>-0.277981</td>\n",
       "      <td>0.131381</td>\n",
       "      <td>-0.264373</td>\n",
       "      <td>0.161799</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>523.466667</td>\n",
       "      <td>1676.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a70ebc32-7ee1-456f-9fa1-bef302fb0e78</th>\n",
       "      <td>-0.213674</td>\n",
       "      <td>0.248164</td>\n",
       "      <td>0.187931</td>\n",
       "      <td>-0.135470</td>\n",
       "      <td>0.145471</td>\n",
       "      <td>0.211850</td>\n",
       "      <td>0.077825</td>\n",
       "      <td>0.131165</td>\n",
       "      <td>-0.311816</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>80.923077</td>\n",
       "      <td>1698.846154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b24c3a33-2952-4ae4-9f2d-643d8fdbc600</th>\n",
       "      <td>-0.259950</td>\n",
       "      <td>0.331705</td>\n",
       "      <td>0.353328</td>\n",
       "      <td>-0.253111</td>\n",
       "      <td>-0.141396</td>\n",
       "      <td>0.189478</td>\n",
       "      <td>-0.271301</td>\n",
       "      <td>0.117444</td>\n",
       "      <td>-0.035993</td>\n",
       "      <td>-0.178271</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>631.525424</td>\n",
       "      <td>1275.474576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d5742c1-77c4-429c-8f6e-ef1262ca5557</th>\n",
       "      <td>-0.266226</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>0.347730</td>\n",
       "      <td>-0.344043</td>\n",
       "      <td>-0.213856</td>\n",
       "      <td>0.288501</td>\n",
       "      <td>-0.077220</td>\n",
       "      <td>0.229046</td>\n",
       "      <td>-0.102184</td>\n",
       "      <td>-0.159140</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>66</td>\n",
       "      <td>240.515152</td>\n",
       "      <td>1277.787879</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8be8e839-6dd0-44e0-b039-170b5b77cf2a</th>\n",
       "      <td>-0.069977</td>\n",
       "      <td>-0.028685</td>\n",
       "      <td>0.461122</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>0.071390</td>\n",
       "      <td>0.129088</td>\n",
       "      <td>-0.153466</td>\n",
       "      <td>0.086815</td>\n",
       "      <td>-0.264927</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>316.625000</td>\n",
       "      <td>1631.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      prompt_vector_0  prompt_vector_1  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94        -0.105305         0.146404   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854        -0.099691         0.317647   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6        -0.233918         0.285974   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9        -0.247697         0.323605   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1        -0.418465         0.338650   \n",
       "...                                               ...              ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c        -0.132189         0.299466   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78        -0.213674         0.248164   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600        -0.259950         0.331705   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557        -0.266226         0.349401   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a        -0.069977        -0.028685   \n",
       "\n",
       "                                      prompt_vector_2  prompt_vector_3  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94         0.244801         0.010134   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854         0.297639        -0.162343   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6         0.382238         0.136774   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9         0.214531         0.088791   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1         0.194245        -0.311205   \n",
       "...                                               ...              ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c         0.317161        -0.080648   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78         0.187931        -0.135470   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600         0.353328        -0.253111   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557         0.347730        -0.344043   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a         0.461122        -0.005824   \n",
       "\n",
       "                                      prompt_vector_4  prompt_vector_5  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94        -0.100589         0.013972   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854        -0.302724         0.090270   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6         0.157068         0.194427   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9        -0.090610         0.141679   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1         0.033230        -0.248920   \n",
       "...                                               ...              ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c        -0.029858         0.324425   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78         0.145471         0.211850   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600        -0.141396         0.189478   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557        -0.213856         0.288501   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a         0.071390         0.129088   \n",
       "\n",
       "                                      prompt_vector_6  prompt_vector_7  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94         0.184923         0.107906   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854         0.017619         0.268344   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6         0.194111         0.320898   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9         0.263739         0.114925   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1         0.005590        -0.200436   \n",
       "...                                               ...              ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c        -0.277981         0.131381   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78         0.077825         0.131165   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600        -0.271301         0.117444   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557        -0.077220         0.229046   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a        -0.153466         0.086815   \n",
       "\n",
       "                                      prompt_vector_8  prompt_vector_9  ...  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94        -0.105608         0.104179  ...   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854        -0.027193         0.128519  ...   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6        -0.298705         0.203647  ...   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9        -0.068034        -0.129276  ...   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1        -0.139080        -0.193729  ...   \n",
       "...                                               ...              ...  ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c        -0.264373         0.161799  ...   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78        -0.311816         0.076470  ...   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600        -0.035993        -0.178271  ...   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557        -0.102184        -0.159140  ...   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a        -0.264927         0.056653  ...   \n",
       "\n",
       "                                      question_match_2  question_match_3  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94                 6                 7   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854                 1                 1   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6                 4                 5   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9                38                36   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1                12                13   \n",
       "...                                                ...               ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c                 8                 8   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78                 6                 7   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600                26                18   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557                36                35   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a                 9                 7   \n",
       "\n",
       "                                      question_match_4  question_match_5  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94                 4                 5   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854                 1                 1   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6                 4                 5   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9                28                48   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1                11                13   \n",
       "...                                                ...               ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c                 8                 6   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78                 5                 6   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600                20                30   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557                37                41   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a                 8                 8   \n",
       "\n",
       "                                      question_match_6  question_match_7  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94                 5                 3   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854                 1                 1   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6                 4                 5   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9                33                51   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1                11                13   \n",
       "...                                                ...               ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c                 8                 5   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78                 6                 5   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600                26                17   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557                37                34   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a                 8                 7   \n",
       "\n",
       "                                      pair_count  avg_prompt_length  \\\n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94          17         455.941176   \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854           1         101.000000   \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6          14         509.285714   \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9         100         159.030000   \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1          25         215.360000   \n",
       "...                                          ...                ...   \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c          15         523.466667   \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78          13          80.923077   \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600          59         631.525424   \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557          66         240.515152   \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a          16         316.625000   \n",
       "\n",
       "                                      avg_answer_length  grade  \n",
       "b73f91f8-732f-4a48-bcbd-eadbbb457a94        1580.352941    NaN  \n",
       "746b8f06-1e89-43b8-b73c-1121eecfc854         347.000000    NaN  \n",
       "30283b91-7fc3-4125-985b-b441f0f489d6        1653.642857    NaN  \n",
       "ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9        1459.850000    NaN  \n",
       "106ffe99-c787-4d09-9076-4ba411eb68b1        1572.080000    NaN  \n",
       "...                                                 ...    ...  \n",
       "2b9cf078-c56b-4020-9197-cd9f7d4f909c        1676.600000    NaN  \n",
       "a70ebc32-7ee1-456f-9fa1-bef302fb0e78        1698.846154    NaN  \n",
       "b24c3a33-2952-4ae4-9f2d-643d8fdbc600        1275.474576    NaN  \n",
       "6d5742c1-77c4-429c-8f6e-ef1262ca5557        1277.787879    NaN  \n",
       "8be8e839-6dd0-44e0-b039-170b5b77cf2a        1631.500000    NaN  \n",
       "\n",
       "[122 rows x 212 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [f\"prompt_vector_{i}\" for i in range(100)]\n",
    "columns += [f\"answer_vector_{i}\" for i in range(100)]\n",
    "columns += [f\"question_match_{i}\" for i in range(8)]\n",
    "columns += [\"pair_count\", \"avg_prompt_length\", \"avg_answer_length\", \"grade\"]\n",
    "\n",
    "dataframe = pd.DataFrame(index=raw_data.keys(), columns=columns)\n",
    "dataframe.apply(our_super_great_row_processor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_fd = open(\"./materials/scores.csv\")\n",
    "grades_csv_reader = csv.reader(grades_fd)\n",
    "\n",
    "for i, row in enumerate(grades_csv_reader):\n",
    "    if i > 0:\n",
    "        key = row[1].strip()\n",
    "        grade = float(row[2].strip())\n",
    "        dataframe.at[key, 'grade'] = grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.apply(pd.to_numeric, errors='coerce')\n",
    "dataframe = dataframe.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    dataframe.drop(columns=['grade']), dataframe['grade'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "train_data = np.asarray(train_data_scaled).astype(np.float32)\n",
    "test_data = np.asarray(test_data_scaled).astype(np.float32)\n",
    "\n",
    "\n",
    "train_labels = np.asarray(train_labels).astype(np.int32)\n",
    "test_labels = np.asarray(test_labels).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1000)              212000    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10000)             10010000  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 10001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10232001 (39.03 MB)\n",
      "Trainable params: 10232001 (39.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu', input_shape=(211,)))\n",
    "model.add(Dense(10000, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 576.4333 - mean_squared_error: 576.4333 - val_loss: 1390.7483 - val_mean_squared_error: 1390.7483\n",
      "Epoch 2/14\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 444.2884 - mean_squared_error: 444.2884 - val_loss: 1743.1145 - val_mean_squared_error: 1743.1145\n",
      "Epoch 3/14\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 448.6510 - mean_squared_error: 448.6510 - val_loss: 1895.3984 - val_mean_squared_error: 1895.3984\n",
      "Epoch 4/14\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 459.4530 - mean_squared_error: 459.4530 - val_loss: 1670.7000 - val_mean_squared_error: 1670.7000\n",
      "Epoch 5/14\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 426.0642 - mean_squared_error: 426.0642 - val_loss: 1466.8289 - val_mean_squared_error: 1466.8289\n",
      "Epoch 6/14\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 428.3716 - mean_squared_error: 428.3716 - val_loss: 1544.4152 - val_mean_squared_error: 1544.4152\n",
      "Epoch 7/14\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 409.5467 - mean_squared_error: 409.5467 - val_loss: 1666.0098 - val_mean_squared_error: 1666.0098\n",
      "Epoch 8/14\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 408.9419 - mean_squared_error: 408.9419 - val_loss: 1649.5168 - val_mean_squared_error: 1649.5168\n",
      "Epoch 9/14\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 399.4060 - mean_squared_error: 399.4060 - val_loss: 1588.8395 - val_mean_squared_error: 1588.8395\n",
      "Epoch 10/14\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 405.3258 - mean_squared_error: 405.3258 - val_loss: 1523.6145 - val_mean_squared_error: 1523.6145\n",
      "Epoch 11/14\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 400.4683 - mean_squared_error: 400.4683 - val_loss: 1627.3684 - val_mean_squared_error: 1627.3684\n",
      "Epoch 12/14\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 389.5550 - mean_squared_error: 389.5550 - val_loss: 1735.8879 - val_mean_squared_error: 1735.8879\n",
      "Epoch 13/14\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 399.1573 - mean_squared_error: 399.1573 - val_loss: 1696.7125 - val_mean_squared_error: 1696.7125\n",
      "Epoch 14/14\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 390.6941 - mean_squared_error: 390.6941 - val_loss: 1628.7605 - val_mean_squared_error: 1628.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28b51eb30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    epochs=14,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
